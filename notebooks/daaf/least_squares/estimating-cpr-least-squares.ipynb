{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "precise-thread",
   "metadata": {},
   "source": [
    "# Estimating Cumulative Periodic Rewards (CPR) using Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-workplace",
   "metadata": {},
   "source": [
    "In order to evaluate a policy, algorithms such as n-step SARSA and Monte Carlo rely on rewards being available for every action.\n",
    "In this notebook, we explore the problem of cumulative periodic rewards - rewards that are made avaiable every K steps, and represent an aggreate over the rewards of the last previous steps.\n",
    "\n",
    "We investigate the method of Least Squares to estimate the true rewards of state action pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "historic-karaoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import os.path\n",
    "import json\n",
    "import getpass\n",
    "import glob\n",
    "from typing import Any, Callable, Sequence, Mapping, Text, Union, Tuple\n",
    "import copy\n",
    "import itertools\n",
    "\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-observation",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-planner",
   "metadata": {},
   "source": [
    "  - Problem ABC\n",
    "  - Difficulty: 3 letters (4 states, 4 actions)\n",
    "  - Reward Period: 2 (every 2 steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "optimum-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dental-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGS = pathlib.Path(\n",
    "    f\"/Users/{getpass.getuser()}/fs/abc/trajectory/L03/1621248247/1621248252\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recognized-guyana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_files(path: pathlib.Path):\n",
    "    return glob.glob(str(os.path.join(path, \"partition-*.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "silent-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logs_as_dataset(path: pathlib.Path):\n",
    "    files = log_files(path)\n",
    "    traj = []\n",
    "    for filename in files:\n",
    "        with open(filename, \"r\") as reader:\n",
    "            for line in reader:\n",
    "                traj.append(json.loads(line))\n",
    "    return traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "arranged-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = load_logs_as_dataset(LOGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "electronic-brain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3860"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fitting-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_id(observation: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Each letter can be a zero or one.\n",
    "    They can only be learned in order.\n",
    "    There is one dummy value of one in the observation.\n",
    "    For two letters:\n",
    "        [1, 0, 0] = 0 (starting state)\n",
    "        [1, 1, 0] = 1\n",
    "        [1, 1, 1] = 2\n",
    "    \"\"\"\n",
    "    return np.sum(observation) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-paste",
   "metadata": {},
   "source": [
    "## Data Validity Completeness\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-thesis",
   "metadata": {},
   "source": [
    "First, let's check if our data vaoid sub-trajectories - because we use TFUniformReplayBuffer, it's does a best effort at ensuring transitions are sampled in order, but there is no guarantee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "friendly-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use permutations\n",
    "# remove any where i > j - we only need one value per combination, because"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "varied-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_tensition(\n",
    "    transitions: Tuple[Tuple, Tuple], num_letters: int\n",
    ") -> Sequence[Tuple[Tuple, Tuple]]:\n",
    "    \"\"\"\n",
    "    Generates a sequence of possible transitions\n",
    "    \"\"\"\n",
    "    for i in range(len(transitions) - 1):\n",
    "        begin_state, begin_action = transitions[i]\n",
    "        end_state, _ = transitions[i + 1]\n",
    "        if begin_state > end_state:\n",
    "            return False\n",
    "        if end_state - begin_state > 1:\n",
    "            return False\n",
    "        if end_state - begin_state == 1 and begin_state != begin_action:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "plastic-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validity_check(logs: Sequence[Any], num_letters: int) -> bool:\n",
    "    invalid = set()\n",
    "    invalid_count = 0\n",
    "\n",
    "    for traj in logs:\n",
    "        # assumed to be 2\n",
    "        steps = len(traj[\"step_type\"])\n",
    "        transitions = []\n",
    "        for step in range(steps):\n",
    "            state = state_id(traj[\"observation\"][step])\n",
    "            action = traj[\"action\"][step]\n",
    "            transitions.append((state, action))\n",
    "        transitions = tuple(transitions)\n",
    "        if not is_valid_tensition(transitions, num_letters):\n",
    "            invalid.add(transitions)\n",
    "            invalid_count += 1\n",
    "    return invalid_count > 1, {\"invalid\": {\"unique\": invalid, \"count\": invalid_count}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "handy-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_invalid, invalid_info = validity_check(logs, num_letters=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "killing-collective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "duplicate-gibson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((2, 1), (3, 1)),\n",
       " ((0, 1), (1, 0)),\n",
       " ((2, 1), (3, 3)),\n",
       " ((0, 3), (1, 0)),\n",
       " ((0, 3), (1, 1)),\n",
       " ((0, 2), (1, 2)),\n",
       " ((2, 3), (3, 1)),\n",
       " ((1, 0), (2, 0)),\n",
       " ((0, 2), (1, 3)),\n",
       " ((2, 1), (3, 2))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(invalid_info[\"invalid\"][\"unique\"])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "arabic-speaking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1966321243523316"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_info[\"invalid\"][\"count\"] / len(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-philip",
   "metadata": {},
   "source": [
    "## Processing: Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-drunk",
   "metadata": {},
   "source": [
    "To solve the problem of estimating cumulative periodic rewards, we'll transform the data into a matrix format that allows us to solve the problem using least squares.\n",
    "\n",
    "Three such representations are explored:\n",
    "\n",
    "1. Presence: $(S_{1},A_{1}), (S_{1}, A_{2}),..(S_{2}, A_{1}),..(S_{n}, A_{n})$ -> in this format, we use a 1 to flag (state, action) pairs present in the sub-sequence and 0 for states that are absent\n",
    "\n",
    "2. Occurence: $(S_{1},A_{1}), (S_{1}, A_{2}),..(S_{2}, A_{1}),..(S_{n}, A_{n})$ -> in this format, we use the number of states each (state, action) pair appears in the sub-sequence\n",
    "\n",
    "3. Both: $(S_{1},A_{1})^{p}, (S_{1}, A_{1})^{o},..(S_{2}, A_{1})^{p}, (S_{2}, A_{1})^{o},..(S_{n}, A_{n})^{p}, (S_{n}, A_{n})^{o}$ -> in this format, we use two factors per (state, action) pair; one to indicate presence, and the other occurence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "irish-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(logs: Sequence[Mapping[Text, Any]], op: Callable[[Any], Any]):\n",
    "    factors, result = [], []\n",
    "    for log in logs:\n",
    "        row, y = op(log)\n",
    "        factors.append(row)\n",
    "        result.append(y)\n",
    "    return tf.convert_to_tensor(factors, tf.float32), tf.convert_to_tensor(\n",
    "        result, tf.float32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "monthly-federation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_type': [1, 1],\n",
       " 'observation': [[1, 0, 0, 0], [1, 0, 0, 0]],\n",
       " 'action': [1, 3],\n",
       " 'policy_info': {'log_probability': [-1.3862943649291992,\n",
       "   -1.3862943649291992]},\n",
       " 'next_step_type': [1, 1],\n",
       " 'reward': [-1.0, -3.0],\n",
       " 'discount': [1.0, 1.0]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "increasing-specification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_presence_transform_op(num_states: int, num_actions: int):\n",
    "    def op(record: Mapping[Text, Any]) -> Tuple[Any, Any]:\n",
    "        row = np.zeros(shape=(num_states, num_actions))\n",
    "        steps = len(record[\"step_type\"])\n",
    "        cpr = sum(record[\"reward\"])\n",
    "        for step in range(steps):\n",
    "            state = state_id(record[\"observation\"][step])\n",
    "            action = record[\"action\"][step]\n",
    "            row[state, action] = 1\n",
    "        return row.flatten(), cpr\n",
    "\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "proprietary-nature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), -4.0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_presence_transform_op(4, 4)(logs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "silver-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_occurence_transform_op(num_states: int, num_actions: int):\n",
    "    def op(record: Mapping[Text, Any]) -> Tuple[Any, Any]:\n",
    "        row = np.zeros(shape=(num_states, num_actions))\n",
    "        steps = len(record[\"step_type\"])\n",
    "        cpr = sum(record[\"reward\"])\n",
    "        for step in range(steps):\n",
    "            state = state_id(record[\"observation\"][step])\n",
    "            action = record[\"action\"][step]\n",
    "            row[state, action] += 1\n",
    "        return row.flatten(), cpr\n",
    "\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "personalized-enterprise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), -4.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_occurence_transform_op(4, 4)(logs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "legendary-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_presence_and_occurence_transform_op(num_states: int, num_actions: int):\n",
    "    def op(record: Mapping[Text, Any]) -> Tuple[Any, Any]:\n",
    "        presence = np.zeros(shape=(num_states, num_actions))\n",
    "        occurrence = np.zeros(shape=(num_states, num_actions))\n",
    "        steps = len(record[\"step_type\"])\n",
    "        cpr = sum(record[\"reward\"])\n",
    "        for step in range(steps):\n",
    "            state = state_id(record[\"observation\"][step])\n",
    "            action = record[\"action\"][step]\n",
    "            presence[state, action] = 1\n",
    "            occurrence[state, action] += 1\n",
    "        return np.concatenate((presence, occurrence), axis=1).flatten(), cpr\n",
    "\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fancy-butler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " -4.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_presence_and_occurence_transform_op(4, 4)(logs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-emphasis",
   "metadata": {},
   "source": [
    "## Least Squares Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "lucky-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_least_squares(\n",
    "    matrix: Union[tf.Tensor, np.ndarray],\n",
    "    rhs: Union[tf.Tensor, np.ndarray],\n",
    "    l2_regularizer: float = 0.5,\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the solution to n variables using Least-Squares.\n",
    "\n",
    "    Args:\n",
    "        matrix: A 2D tensor, A, shaped m x n.\n",
    "        rhs: A set of outcomes, b, shaped m.\n",
    "        l2_regularizer: A regularization factor.\n",
    "\n",
    "    Returns:\n",
    "        The solution x to the least-squares problem Ax=b, shaped n.\n",
    "    \"\"\"\n",
    "    shape = tf.shape(matrix)\n",
    "    if tf.size(shape) != 2:\n",
    "        raise ValueError(f\"Only 2D tensors are supported. Got shape: {shape}\")\n",
    "\n",
    "    matrix = tf.expand_dims(matrix, axis=0)\n",
    "    rhs = tf.expand_dims(rhs, axis=-1)\n",
    "    try:\n",
    "        result = tf.linalg.lstsq(matrix=matrix, rhs=rhs, l2_regularizer=l2_regularizer)\n",
    "    except tf.errors.InvalidArgumentError as err:\n",
    "        logging.error(\"LS failed!\")\n",
    "        return None\n",
    "    return tf.squeeze(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "approximate-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(\n",
    "    pred: Union[tf.Tensor, np.ndarray],\n",
    "    actual: Union[tf.Tensor, np.ndarray],\n",
    "    mask: Union[tf.Tensor, np.ndarray] = None,\n",
    ") -> tf.Tensor:\n",
    "    if mask is None:\n",
    "        mask = tf.ones_like(pred)\n",
    "    mask = tf.cast(mask, dtype=tf.bool)\n",
    "    y_pred = tf.cast(tf.boolean_mask(pred, mask), tf.float32)\n",
    "    y_actual = tf.cast(tf.boolean_mask(actual, mask), tf.float32)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.pow(y_pred - y_actual, 2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "white-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_single_factor_matrix(matrix, num_states: int, num_actions: int):\n",
    "    return tf.reshape(matrix, shape=(num_states, num_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "african-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_rtable = np.array(\n",
    "    [\n",
    "        [0.0, -1.0, -2.0, -3.0],\n",
    "        [-3.0, 0.0, -1.0, -2.0],\n",
    "        [-2.0, -3.0, 0.0, -1.0],\n",
    "        [-1.0, -1.0, -1.0, 0.0],\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-shade",
   "metadata": {},
   "source": [
    "### Presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "unlikely-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, rhs = preprocessing(\n",
    "    logs, op=create_presence_transform_op(num_states=4, num_actions=4)\n",
    ")\n",
    "factors = solve_least_squares(matrix=matrix, rhs=rhs, l2_regularizer=0.0)\n",
    "if factors is not None:\n",
    "    result_presence = reshape_single_factor_matrix(factors, num_states=4, num_actions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "lightweight-asset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.1023725 , -1.0286595 , -2.150843  , -3.3252237 ],\n",
       "       [-3.285166  ,  0.07678866, -1.0206928 , -2.0397308 ],\n",
       "       [-2.1272457 , -3.3301082 ,  0.06442698, -1.0141504 ],\n",
       "       [-1.0860469 , -1.098391  , -1.079862  ,  0.06730542]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "polyphonic-miller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0., -1., -2., -3.],\n",
       "       [-3.,  0., -1., -2.],\n",
       "       [-2., -3.,  0., -1.],\n",
       "       [-1., -1., -1.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.rint(result_presence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "comprehensive-crazy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.15543391>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(result_presence, true_rtable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-renaissance",
   "metadata": {},
   "source": [
    "### Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "binary-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, rhs = preprocessing(\n",
    "    logs, op=create_occurence_transform_op(num_states=4, num_actions=4)\n",
    ")\n",
    "factors = solve_least_squares(matrix=matrix, rhs=rhs, l2_regularizer=0.0)\n",
    "if factors is not None:\n",
    "    result_occurrence = reshape_single_factor_matrix(\n",
    "        factors, num_states=4, num_actions=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ambient-charleston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 8.9562590e-08, -9.9999982e-01, -1.9999999e+00, -3.0000000e+00],\n",
       "       [-2.9999998e+00,  3.2102793e-08, -1.0000000e+00, -2.0000005e+00],\n",
       "       [-1.9999996e+00, -3.0000000e+00,  1.2154199e-07, -1.0000002e+00],\n",
       "       [-1.0000001e+00, -1.0000002e+00, -9.9999982e-01, -7.1422448e-08]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "danish-audio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0., -1., -2., -3.],\n",
       "       [-3.,  0., -1., -2.],\n",
       "       [-2., -3.,  0., -1.],\n",
       "       [-1., -1., -1., -0.]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.rint(result_occurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "boolean-perfume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0110598e-07>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(result_occurrence, true_rtable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-taxation",
   "metadata": {},
   "source": [
    "### Both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acquired-sweden",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LS failed!\n"
     ]
    }
   ],
   "source": [
    "matrix, rhs = preprocessing(\n",
    "    logs, op=create_presence_and_occurence_transform_op(num_states=4, num_actions=4)\n",
    ")\n",
    "factors = solve_least_squares(matrix=matrix, rhs=rhs, l2_regularizer=0.0)\n",
    "if factors is not None:\n",
    "    result_presence = reshape_single_factor_matrix(\n",
    "        factors, num_states=4, num_actions=4 * 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-donor",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "\n",
    "  - Both the presence and occurence format reach reward estimates that are close to the true reward values.\n",
    "  - Occurence has a much narrow gap to the true values, with an RMSE almost equal to zero.\n",
    "  - The representation that relies on both has no solution - every factor for occurence should be 1.\n",
    "  \n",
    "  \n",
    "The fact that occurence has a much closer result is expected, since transitions containing the same (state, action) pair won't would require a different factor variable otherwise. This also likely the reason why the presence representation has more different values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-holmes",
   "metadata": {},
   "source": [
    "## How much data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-integration",
   "metadata": {},
   "source": [
    "Knowing that the occurence representation gives reasonable estimates of reward, let's to evaluate the volume of data against error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "pleasant-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_error_per_data(\n",
    "    logs,\n",
    "    percentage: float,\n",
    "    iterations: int,\n",
    "    num_letters: int,\n",
    "    true_rtable: Union[tf.Tensor, np.ndarray],\n",
    "):\n",
    "    num_states = num_letters + 1\n",
    "    num_actions = num_letters + 1\n",
    "    errors = []\n",
    "    total = len(logs)\n",
    "    matrix, rhs = preprocessing(\n",
    "        logs,\n",
    "        op=create_occurence_transform_op(\n",
    "            num_states=num_states, num_actions=num_actions\n",
    "        ),\n",
    "    )\n",
    "    print(f\"perc: {percentage}\")\n",
    "    for i in range(iterations):\n",
    "        indices = tf.constant(\n",
    "            np.random.choice(range(total), int(percentage * total)).tolist(), tf.int64\n",
    "        )\n",
    "        sample_matrix = tf.gather(matrix, indices)\n",
    "        sample_rhs = tf.gather(rhs, indices)\n",
    "        ls = solve_least_squares(\n",
    "            matrix=sample_matrix, rhs=sample_rhs, l2_regularizer=0.0\n",
    "        )\n",
    "        result_occurence = reshape_single_factor_matrix(\n",
    "            ls, num_states=num_states, num_actions=num_actions\n",
    "        )\n",
    "        errors.append(rmse(result_occurence, true_rtable))\n",
    "    return np.mean(errors), np.std(errors, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "considered-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_over_data_perc(logs, num_letters, percentages, true_rtable, iterations):\n",
    "    errors = []\n",
    "    stds = []\n",
    "    for perc in percentages:\n",
    "        error_mean, error_std = estimate_error_per_data(\n",
    "            logs,\n",
    "            percentage=perc,\n",
    "            iterations=iterations,\n",
    "            num_letters=num_letters,\n",
    "            true_rtable=true_rtable,\n",
    "        )\n",
    "        errors.append(error_mean)\n",
    "        stds.append(error_std)\n",
    "    return np.array(errors), np.array(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "floral-pocket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc: 0.1\n",
      "perc: 0.3\n",
      "perc: 0.5\n",
      "perc: 0.7\n",
      "perc: 9.0\n",
      "CPU times: user 2.73 s, sys: 114 ms, total: 2.85 s\n",
      "Wall time: 2.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iteartions = 100\n",
    "percentages = (0.1, 0.3, 0.5, 0.7, 9.0)\n",
    "errors, stds = error_over_data_perc(\n",
    "    logs,\n",
    "    num_letters=3,\n",
    "    percentages=percentages,\n",
    "    true_rtable=true_rtable,\n",
    "    iterations=iteartions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "scientific-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "sme = stds / np.sqrt(iteartions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "inappropriate-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metric_figure_from_values(steps, values, title, ax, label, ci=None):\n",
    "    ax.set_title(title)\n",
    "    ax.plot(steps, values, label=label)\n",
    "    if ci is not None:\n",
    "        upper_ci = values + ci\n",
    "        lower_ci = values - ci\n",
    "        ax.fill_between(steps, lower_ci, upper_ci, alpha=0.4, label=\"CI\")\n",
    "    ax.ticklabel_format(style=\"sci\", scilimits=(1, 2))\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "parliamentary-payday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Data % v RMSE'}>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "generate_metric_figure_from_values(\n",
    "    percentages, errors, title=\"Data % v RMSE\", ax=ax, label=\"error\", ci=sme\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-kinase",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "We find that:\n",
    "  - Occurrence as a representation factor for (state, action) pairs gives reasonable approximiate results.\n",
    "  - The standard mean error for the estimate is small with as little as 10% of 43,663 transitions (each with two steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
